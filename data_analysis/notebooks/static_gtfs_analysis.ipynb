{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ff509f7",
   "metadata": {},
   "source": [
    "# Notebook with GTFS methods\n",
    "\n",
    "Goals: \n",
    "\n",
    "* Make a way to calculate the scheduled number of current active trips given a date, time, and route. \n",
    "    - Take datetime and find what services are active on that date \n",
    "    - Find what trips run on those services + route \n",
    "    - Find which of those trips are \"in progress\" per stop_times\n",
    "* ~Output most common shape by route~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ffac7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "\n",
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import requests\n",
    "import pendulum\n",
    "from io import BytesIO\n",
    "import shapely\n",
    "import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a22d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if \"private\", will assume you have write permissions and allow you to write; else will not attempt to write files\n",
    "BUCKET_TYPE = \"private\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b41f5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local \n",
    "# CTA_GTFS = zipfile.ZipFile('cta_gtfs_20220509.zip')\n",
    "# s3\n",
    "# follow https://pythonguides.com/download-zip-file-from-url-using-python/\n",
    "# CTA_GTFS = zipfile.ZipFile(BytesIO(requests.get('https://chn-ghost-buses-public.s3.us-east-2.amazonaws.com/cta_static_gtfs/cta_gtfs_20220509.zip').content))\n",
    "# cta website\n",
    "\n",
    "# VERSION_ID = '20220718'\n",
    "\n",
    "RTD_GTFS = zipfile.ZipFile('../../utils/utils/gtfs/google_transit_20231504.zip') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60357a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTFSFeed:\n",
    "    def __init__(self, gtfs_zipfile):\n",
    "        self.gtfs_zipfile = gtfs_zipfile\n",
    "        try: \n",
    "            with self.gtfs_zipfile.open('stops.txt') as file:\n",
    "                    self.stops = pd.read_csv(file, dtype = 'object')\n",
    "                    print(\"stops.txt loaded\")\n",
    "            with self.gtfs_zipfile.open('stop_times.txt') as file:\n",
    "                    self.stop_times = pd.read_csv(file, dtype = 'object')\n",
    "                    print(\"stop_times.txt loaded\")\n",
    "            with self.gtfs_zipfile.open('routes.txt') as file:\n",
    "                    self.routes = pd.read_csv(file, dtype = 'object')\n",
    "                    print(\"routes.txt loaded\")\n",
    "            with self.gtfs_zipfile.open('trips.txt') as file:\n",
    "                    self.trips = pd.read_csv(file, dtype = 'object')\n",
    "                    print(\"trips.txt loaded\")\n",
    "        except KeyError as e:\n",
    "            print(\"GTFS is missing required file\")\n",
    "            print(e)\n",
    "        if 'calendar.txt' in self.gtfs_zipfile.namelist():\n",
    "                with self.gtfs_zipfile.open('calendar.txt') as file:\n",
    "                        self.calendar = pd.read_csv(file, dtype = 'object')\n",
    "                        print(\"calendar.txt loaded\")\n",
    "        else:\n",
    "            print(\"no calendar.txt found\")\n",
    "        if 'calendar_dates.txt' in self.gtfs_zipfile.namelist():\n",
    "                with self.gtfs_zipfile.open('calendar_dates.txt') as file:\n",
    "                        self.calendar_dates = pd.read_csv(file, dtype = 'object')\n",
    "                        print(\"calendar_dates.txt loaded\")\n",
    "        else:\n",
    "            print(\"no calendar_dates.txt found\")\n",
    "        if 'shapes.txt' in self.gtfs_zipfile.namelist():\n",
    "                with self.gtfs_zipfile.open('shapes.txt') as file:\n",
    "                        self.shapes = pd.read_csv(file, dtype = 'object')\n",
    "                        print(\"shapes.txt loaded\")\n",
    "        else:\n",
    "            print(\"no shapes.txt found\")\n",
    "        if 'feed_info.txt' in self.gtfs_zipfile.namelist():\n",
    "                with self.gtfs_zipfile.open('feed_info.txt') as file:\n",
    "                        self.feed_info = pd.read_csv(file, dtype = 'object')\n",
    "                        print(\"feed_info.txt loaded\")\n",
    "        else:\n",
    "            print(\"no feed_info.txt found\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25a4870d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stops.txt loaded\n",
      "stop_times.txt loaded\n",
      "routes.txt loaded\n",
      "trips.txt loaded\n",
      "calendar.txt loaded\n",
      "calendar_dates.txt loaded\n",
      "shapes.txt loaded\n",
      "feed_info.txt loaded\n"
     ]
    }
   ],
   "source": [
    "data = GTFSFeed(RTD_GTFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9913b3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>monday</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>wednesday</th>\n",
       "      <th>thursday</th>\n",
       "      <th>friday</th>\n",
       "      <th>saturday</th>\n",
       "      <th>sunday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SA_merged_114569136</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SA_3340</td>\n",
       "      <td>20230403</td>\n",
       "      <td>20230501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MT_3340</td>\n",
       "      <td>20230403</td>\n",
       "      <td>20230501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WK_3340</td>\n",
       "      <td>20230403</td>\n",
       "      <td>20230501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR_merged_114569130</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MT_merged_114569127</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FR_merged_114569123</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FR_3340</td>\n",
       "      <td>20230403</td>\n",
       "      <td>20230501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WK_merged_114569132</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WK_merged_114569125</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SU_merged_114569126</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P_Fri_merged_114569135</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SU_3340</td>\n",
       "      <td>20230403</td>\n",
       "      <td>20230501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P_Fri_merged_114569128</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DPSWK_merged_114569124</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DPSWK_merged_114569131</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SA_merged_114569129</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MT_merged_114569134</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                service_id start_date  end_date monday tuesday wednesday  \\\n",
       "0      SA_merged_114569136   20230528  20230819      0       0         0   \n",
       "1                  SA_3340   20230403  20230501      0       0         0   \n",
       "2                  MT_3340   20230403  20230501      1       1         1   \n",
       "3                  WK_3340   20230403  20230501      1       1         1   \n",
       "4      FR_merged_114569130   20230528  20230819      0       0         0   \n",
       "5      MT_merged_114569127   20230108  20230527      1       1         1   \n",
       "6      FR_merged_114569123   20230108  20230527      0       0         0   \n",
       "7                  FR_3340   20230403  20230501      0       0         0   \n",
       "8      WK_merged_114569132   20230528  20230819      1       1         1   \n",
       "9      WK_merged_114569125   20230108  20230527      1       1         1   \n",
       "10     SU_merged_114569126   20230108  20230527      0       0         0   \n",
       "11  P_Fri_merged_114569135   20230528  20230819      0       0         0   \n",
       "12                 SU_3340   20230403  20230501      0       0         0   \n",
       "13  P_Fri_merged_114569128   20230108  20230527      0       0         0   \n",
       "14  DPSWK_merged_114569124   20230108  20230527      1       1         1   \n",
       "15  DPSWK_merged_114569131   20230528  20230819      1       1         1   \n",
       "16     SA_merged_114569129   20230108  20230527      0       0         0   \n",
       "17     SU_merged_114569133   20230528  20230819      0       0         0   \n",
       "18     MT_merged_114569134   20230528  20230819      1       1         1   \n",
       "\n",
       "   thursday friday saturday sunday  \n",
       "0         0      0        1      0  \n",
       "1         0      0        1      0  \n",
       "2         1      0        0      0  \n",
       "3         1      1        0      0  \n",
       "4         0      1        0      0  \n",
       "5         1      0        0      0  \n",
       "6         0      1        0      0  \n",
       "7         0      1        0      0  \n",
       "8         1      1        0      0  \n",
       "9         1      1        0      0  \n",
       "10        0      0        0      1  \n",
       "11        0      1        0      0  \n",
       "12        0      0        0      1  \n",
       "13        0      1        0      0  \n",
       "14        1      1        0      0  \n",
       "15        1      1        0      0  \n",
       "16        0      0        1      0  \n",
       "17        0      0        0      1  \n",
       "18        1      0        0      0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ba1950a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_id</th>\n",
       "      <th>date</th>\n",
       "      <th>exception_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WK_merged_114569132</td>\n",
       "      <td>20230704</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WK_merged_114569132</td>\n",
       "      <td>20230529</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_Fri_merged_114569135</td>\n",
       "      <td>20230704</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P_Fri_merged_114569135</td>\n",
       "      <td>20230529</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DPSWK_merged_114569131</td>\n",
       "      <td>20230704</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DPSWK_merged_114569131</td>\n",
       "      <td>20230529</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>20230704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>20230529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MT_merged_114569134</td>\n",
       "      <td>20230704</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MT_merged_114569134</td>\n",
       "      <td>20230529</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               service_id      date exception_type\n",
       "0     WK_merged_114569132  20230704              2\n",
       "1     WK_merged_114569132  20230529              2\n",
       "2  P_Fri_merged_114569135  20230704              2\n",
       "3  P_Fri_merged_114569135  20230529              2\n",
       "4  DPSWK_merged_114569131  20230704              2\n",
       "5  DPSWK_merged_114569131  20230529              2\n",
       "6     SU_merged_114569133  20230704              1\n",
       "7     SU_merged_114569133  20230529              1\n",
       "8     MT_merged_114569134  20230704              2\n",
       "9     MT_merged_114569134  20230529              2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.calendar_dates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2c84c30",
   "metadata": {},
   "source": [
    "## Basic data transformations\n",
    "\n",
    "Ex. creating actual timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c80c1328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_timestamp(s, date):\n",
    "#     parts = s.split(':')\n",
    "#     assert len(parts)==3\n",
    "#     if int(parts[0]) > 23:\n",
    "#         num_parts = [int(parts[0]) - 24, int(parts[1]), int(parts[2])]\n",
    "#     else:\n",
    "#         num_parts = [int(parts[0]), int(parts[1]), int(parts[2])]\n",
    "#     return pendulum.datetime(year = date.year, month = date.month, day = date.day, hour = num_parts[0], minute = num_parts[1], second = num_parts[2])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "740f84c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hour(s):\n",
    "    parts = s.split(':')\n",
    "    assert len(parts)==3\n",
    "    hour = int(parts[0])\n",
    "    if hour >= 24:\n",
    "        hour -= 24\n",
    "    return hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b9217f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dates_hours(data):\n",
    "    # convert string dates to actual datetimes in calendar.txt and calendar_dates.txt\n",
    "    data.calendar['start_date_dt'] = data.calendar['start_date'].apply(lambda x: pendulum.from_format(x, 'YYYYMMDD'))\n",
    "    data.calendar['end_date_dt'] = data.calendar['end_date'].apply(lambda x: pendulum.from_format(x, 'YYYYMMDD'))\n",
    "    data.calendar_dates['date_dt'] = data.calendar_dates['date'].apply(lambda x: pendulum.from_format(x, 'YYYYMMDD'))\n",
    "    \n",
    "    # extract hour from stop_times timestamps \n",
    "    data.stop_times['arrival_hour'] = data.stop_times.arrival_time.apply(lambda x: get_hour(x))\n",
    "    data.stop_times['departure_hour'] = data.stop_times.departure_time.apply(lambda x: get_hour(x))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a43200f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = format_dates_hours(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96410a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_headsign</th>\n",
       "      <th>pickup_type</th>\n",
       "      <th>drop_off_type</th>\n",
       "      <th>shape_dist_traveled</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>arrival_hour</th>\n",
       "      <th>departure_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>114458892</td>\n",
       "      <td>19:59:00</td>\n",
       "      <td>20:02:00</td>\n",
       "      <td>34534</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>114357406</td>\n",
       "      <td>06:59:00</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>13703</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>114357407</td>\n",
       "      <td>16:59:00</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>13703</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6379</th>\n",
       "      <td>114443077</td>\n",
       "      <td>14:59:00</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>34539</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6439</th>\n",
       "      <td>114443076</td>\n",
       "      <td>13:59:00</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>34539</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439032</th>\n",
       "      <td>114454314</td>\n",
       "      <td>20:59:00</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>13703</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439334</th>\n",
       "      <td>114454311</td>\n",
       "      <td>07:59:00</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>13703</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441727</th>\n",
       "      <td>114360586</td>\n",
       "      <td>20:59:00</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>35033</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441829</th>\n",
       "      <td>114568212</td>\n",
       "      <td>22:59:45</td>\n",
       "      <td>23:03:15</td>\n",
       "      <td>23061</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442402</th>\n",
       "      <td>114362496</td>\n",
       "      <td>20:58:00</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>11489</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           trip_id arrival_time departure_time stop_id stop_sequence  \\\n",
       "651      114458892     19:59:00       20:02:00   34534            26   \n",
       "2317     114357406     06:59:00       07:00:00   13703            22   \n",
       "2389     114357407     16:59:00       17:00:00   13703            22   \n",
       "6379     114443077     14:59:00       15:00:00   34539            42   \n",
       "6439     114443076     13:59:00       14:00:00   34539            42   \n",
       "...            ...          ...            ...     ...           ...   \n",
       "1439032  114454314     20:59:00       21:00:00   13703            22   \n",
       "1439334  114454311     07:59:00       08:00:00   13703            22   \n",
       "1441727  114360586     20:59:00       21:00:00   35033             1   \n",
       "1441829  114568212     22:59:45       23:03:15   23061             7   \n",
       "1442402  114362496     20:58:00       21:00:00   11489            20   \n",
       "\n",
       "        stop_headsign pickup_type drop_off_type shape_dist_traveled timepoint  \\\n",
       "651               NaN         NaN           NaN                 NaN       NaN   \n",
       "2317              NaN         NaN           NaN                 NaN       NaN   \n",
       "2389              NaN         NaN           NaN                 NaN       NaN   \n",
       "6379              NaN         NaN           NaN                 NaN       NaN   \n",
       "6439              NaN         NaN           NaN                 NaN       NaN   \n",
       "...               ...         ...           ...                 ...       ...   \n",
       "1439032           NaN         NaN           NaN                 NaN       NaN   \n",
       "1439334           NaN         NaN           NaN                 NaN       NaN   \n",
       "1441727           NaN         NaN             1                 NaN       NaN   \n",
       "1441829           NaN         NaN           NaN                 NaN       NaN   \n",
       "1442402           NaN         NaN           NaN                 NaN       NaN   \n",
       "\n",
       "         arrival_hour  departure_hour  \n",
       "651                19              20  \n",
       "2317                6               7  \n",
       "2389               16              17  \n",
       "6379               14              15  \n",
       "6439               13              14  \n",
       "...               ...             ...  \n",
       "1439032            20              21  \n",
       "1439334             7               8  \n",
       "1441727            20              21  \n",
       "1441829            22              23  \n",
       "1442402            20              21  \n",
       "\n",
       "[476 rows x 12 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that there are no dwell periods that cross hour boundary\n",
    "# 476 rows - arrive at 59, leave a minute or two later. 476 instances.\n",
    "data.stop_times[data.stop_times.arrival_hour != data.stop_times.departure_hour]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "89ad4649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trip_summary(data):\n",
    "    # construct a datetime index that has every day between calendar start and end \n",
    "    calendar_date_range = pd.DataFrame(pd.date_range(min(data.calendar.start_date_dt), max(data.calendar.end_date_dt)), columns = ['raw_date'])\n",
    "    \n",
    "    # cross join calendar index with actual calendar to get all combos of possible dates & services \n",
    "    calendar_cross = calendar_date_range.merge(data.calendar, how = \"cross\")\n",
    "    \n",
    "    # extract day of week from date index date\n",
    "    calendar_cross['dayofweek'] = calendar_cross['raw_date'].dt.dayofweek\n",
    "    \n",
    "    # take wide calendar data (one col per day of week) and make it long (one row per day of week)\n",
    "    actual_service = calendar_cross.melt(id_vars = ['raw_date', 'start_date_dt', 'end_date_dt', 'start_date', 'end_date', 'service_id', 'dayofweek'], var_name = 'cal_dayofweek', value_name = 'cal_val')\n",
    "    \n",
    "    # map the calendar input strings to day of week integers to align w pandas dayofweek output\n",
    "    actual_service['cal_daynum'] = actual_service['cal_dayofweek'].map({\n",
    "        'monday': 0,\n",
    "        'tuesday': 1,\n",
    "        'wednesday': 2,\n",
    "        'thursday': 3,\n",
    "        'friday': 4,\n",
    "        'saturday': 5,\n",
    "        'sunday': 6\n",
    "    })\n",
    "    \n",
    "    # now check for rows that \"work\"\n",
    "    # i.e., the day of week matches between datetime index & calendar input\n",
    "    # and the datetime index is between the calendar row's start and end dates\n",
    "    actual_service = actual_service[(actual_service.dayofweek == actual_service.cal_daynum) & \n",
    "                                   (actual_service.start_date_dt <= actual_service.raw_date) &\n",
    "                                   (actual_service.end_date_dt >= actual_service.raw_date)]\n",
    "    \n",
    "    # now merge in calendar dates to the datetime index to get overrides\n",
    "    actual_service = actual_service.merge(data.calendar_dates, how = 'outer', left_on = ['raw_date', 'service_id'], right_on = ['date_dt', 'service_id'])\n",
    "    \n",
    "    # now add a service happened flag for dates where the schedule indicates that this service occurred\n",
    "    # i.e.: calendar has a service indicator of 1 and there's no exception type from calendar_dates\n",
    "    # OR calendar_dates has exception type of 1\n",
    "    # otherwise no service \n",
    "    # https://stackoverflow.com/questions/21415661/logical-operators-for-boolean-indexing-in-pandas\n",
    "    actual_service['service_happened'] = ((actual_service['cal_val'] == '1') & \n",
    "                                          actual_service['exception_type'].isnull()) | (actual_service['exception_type'] == '1')\n",
    "\n",
    "    \n",
    "    # now fill in rows where calendar_dates had a date outside the bounds of the datetime index, so raw_date is always populated\n",
    "    actual_service['raw_date'] = actual_service['raw_date'].fillna(actual_service['date_dt'])\n",
    "    \n",
    "    # filter to only rows where service occurred\n",
    "    service_happened = actual_service[actual_service.service_happened]\n",
    "    \n",
    "    # join trips to only service that occurred\n",
    "    trips_happened = data.trips.merge(service_happened, how = 'left', on = 'service_id')\n",
    "    \n",
    "    # get only the trip / hour combos that actually occurred\n",
    "    trip_stop_hours = data.stop_times[['trip_id', 'arrival_hour']].drop_duplicates()\n",
    "    \n",
    "    # now join\n",
    "    # result has one row per date + row from trips.txt (incl. route) + hour\n",
    "    trip_summary = trips_happened.merge(trip_stop_hours, how = \"left\", on = \"trip_id\")\n",
    "    \n",
    "    return trip_summary\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "35fce10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_summary = make_trip_summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb947dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_id                                     object\n",
      "route_id                                     object\n",
      "direction_id                                 object\n",
      "trip_headsign                                object\n",
      "shape_id                                     object\n",
      "service_id                                   object\n",
      "trip_id                                      object\n",
      "raw_date            datetime64[ns, Timezone('UTC')]\n",
      "start_date_dt       datetime64[ns, Timezone('UTC')]\n",
      "end_date_dt         datetime64[ns, Timezone('UTC')]\n",
      "start_date                                   object\n",
      "end_date                                     object\n",
      "dayofweek                                     int64\n",
      "cal_dayofweek                                object\n",
      "cal_val                                      object\n",
      "cal_daynum                                    int64\n",
      "date                                         object\n",
      "exception_type                               object\n",
      "date_dt             datetime64[ns, Timezone('UTC')]\n",
      "service_happened                               bool\n",
      "arrival_hour                                  int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>direction_id</th>\n",
       "      <th>trip_headsign</th>\n",
       "      <th>shape_id</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>raw_date</th>\n",
       "      <th>start_date_dt</th>\n",
       "      <th>end_date_dt</th>\n",
       "      <th>...</th>\n",
       "      <th>end_date</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>cal_dayofweek</th>\n",
       "      <th>cal_val</th>\n",
       "      <th>cal_daynum</th>\n",
       "      <th>date</th>\n",
       "      <th>exception_type</th>\n",
       "      <th>date_dt</th>\n",
       "      <th>service_happened</th>\n",
       "      <th>arrival_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b_76  4</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>US36 &amp; Bfld</td>\n",
       "      <td>1241914</td>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>114458891</td>\n",
       "      <td>2023-05-29 00:00:00+00:00</td>\n",
       "      <td>2023-05-28 00:00:00+00:00</td>\n",
       "      <td>2023-08-19 00:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>20230819</td>\n",
       "      <td>0</td>\n",
       "      <td>monday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20230529</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-29 00:00:00+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b_76  4</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>US36 &amp; Bfld</td>\n",
       "      <td>1241914</td>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>114458891</td>\n",
       "      <td>2023-05-29 00:00:00+00:00</td>\n",
       "      <td>2023-05-28 00:00:00+00:00</td>\n",
       "      <td>2023-08-19 00:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>20230819</td>\n",
       "      <td>0</td>\n",
       "      <td>monday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20230529</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-29 00:00:00+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b_76  4</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>US36 &amp; Bfld</td>\n",
       "      <td>1241914</td>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>114458891</td>\n",
       "      <td>2023-07-04 00:00:00+00:00</td>\n",
       "      <td>2023-05-28 00:00:00+00:00</td>\n",
       "      <td>2023-08-19 00:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>20230819</td>\n",
       "      <td>1</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20230704</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-07-04 00:00:00+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b_76  4</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>US36 &amp; Bfld</td>\n",
       "      <td>1241914</td>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>114458891</td>\n",
       "      <td>2023-07-04 00:00:00+00:00</td>\n",
       "      <td>2023-05-28 00:00:00+00:00</td>\n",
       "      <td>2023-08-19 00:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>20230819</td>\n",
       "      <td>1</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20230704</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-07-04 00:00:00+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b_76  4</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>US36 &amp; Bfld</td>\n",
       "      <td>1241914</td>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>114458891</td>\n",
       "      <td>2023-05-28 00:00:00+00:00</td>\n",
       "      <td>2023-05-28 00:00:00+00:00</td>\n",
       "      <td>2023-08-19 00:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>20230819</td>\n",
       "      <td>6</td>\n",
       "      <td>sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  block_id route_id direction_id trip_headsign shape_id           service_id  \\\n",
       "0  b_76  4       76            0   US36 & Bfld  1241914  SU_merged_114569133   \n",
       "1  b_76  4       76            0   US36 & Bfld  1241914  SU_merged_114569133   \n",
       "2  b_76  4       76            0   US36 & Bfld  1241914  SU_merged_114569133   \n",
       "3  b_76  4       76            0   US36 & Bfld  1241914  SU_merged_114569133   \n",
       "4  b_76  4       76            0   US36 & Bfld  1241914  SU_merged_114569133   \n",
       "\n",
       "     trip_id                  raw_date             start_date_dt  \\\n",
       "0  114458891 2023-05-29 00:00:00+00:00 2023-05-28 00:00:00+00:00   \n",
       "1  114458891 2023-05-29 00:00:00+00:00 2023-05-28 00:00:00+00:00   \n",
       "2  114458891 2023-07-04 00:00:00+00:00 2023-05-28 00:00:00+00:00   \n",
       "3  114458891 2023-07-04 00:00:00+00:00 2023-05-28 00:00:00+00:00   \n",
       "4  114458891 2023-05-28 00:00:00+00:00 2023-05-28 00:00:00+00:00   \n",
       "\n",
       "                end_date_dt  ...  end_date dayofweek  cal_dayofweek cal_val  \\\n",
       "0 2023-08-19 00:00:00+00:00  ...  20230819         0         monday       0   \n",
       "1 2023-08-19 00:00:00+00:00  ...  20230819         0         monday       0   \n",
       "2 2023-08-19 00:00:00+00:00  ...  20230819         1        tuesday       0   \n",
       "3 2023-08-19 00:00:00+00:00  ...  20230819         1        tuesday       0   \n",
       "4 2023-08-19 00:00:00+00:00  ...  20230819         6         sunday       1   \n",
       "\n",
       "  cal_daynum      date exception_type                   date_dt  \\\n",
       "0          0  20230529              1 2023-05-29 00:00:00+00:00   \n",
       "1          0  20230529              1 2023-05-29 00:00:00+00:00   \n",
       "2          1  20230704              1 2023-07-04 00:00:00+00:00   \n",
       "3          1  20230704              1 2023-07-04 00:00:00+00:00   \n",
       "4          6       NaN            NaN                       NaT   \n",
       "\n",
       "  service_happened  arrival_hour  \n",
       "0             True             8  \n",
       "1             True             9  \n",
       "2             True             8  \n",
       "3             True             9  \n",
       "4             True             8  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trip_summary.dtypes)\n",
    "trip_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ac7ddd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Merged-31664M31661-20230415-035754-Jan23 and May23'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feed_info.feed_version[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d812de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION_ID = data.feed_info.feed_version[0]\n",
    "def summarize_and_save(trip_summary): \n",
    "    # now group to get trips by hour by date by route\n",
    "    route_daily_hourly_summary = trip_summary.groupby(by = ['raw_date', 'route_id', 'arrival_hour'])['trip_id'].count().reset_index()\n",
    "\n",
    "    route_daily_hourly_summary.rename(columns = {'arrival_hour': 'hour', 'trip_id': 'trip_count', 'raw_date': 'date'}, inplace = True)\n",
    "    route_daily_hourly_summary.date = route_daily_hourly_summary.date.dt.date\n",
    "    if BUCKET_TYPE == \"private\":\n",
    "        route_daily_hourly_summary.to_csv(f's3://rtd-ghost-buses-{BUCKET_TYPE}/schedule_summaries/route_level/schedule_route_daily_hourly_summary_{VERSION_ID}.csv', index = False)\n",
    "    \n",
    "    # now group to get trips by hour by date by route by *direction*\n",
    "    route_dir_daily_hourly_summary = trip_summary.groupby(by = ['raw_date', 'route_id', 'direction_id', 'arrival_hour'])['trip_id'].count().reset_index()\n",
    "\n",
    "    route_dir_daily_hourly_summary.rename(columns = {'arrival_hour': 'hour', 'trip_id': 'trip_count', 'raw_date': 'date'}, inplace = True)\n",
    "    route_dir_daily_hourly_summary.date = route_dir_daily_hourly_summary.date.dt.date\n",
    "    if BUCKET_TYPE == \"private\":\n",
    "        route_dir_daily_hourly_summary.to_csv(f's3://rtd-ghost-buses-{BUCKET_TYPE}/schedule_summaries/route_dir_level/schedule_route_dir_daily_hourly_summary_{VERSION_ID}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ae71821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_and_save(trip_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dfd3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "221fd612",
   "metadata": {},
   "source": [
    "## Most common shape by route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba63340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get trip count by route, direction, shape id\n",
    "trips_by_rte_direction = data.trips.groupby(['route_id', 'shape_id', 'direction_id'])['trip_id'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7669b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only most common shape id by route, direction\n",
    "# follow: https://stackoverflow.com/a/54041328\n",
    "most_common_shapes = trips_by_rte_direction.sort_values('trip_id').drop_duplicates(['route_id','direction_id'],keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cb40d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get additional route attributes\n",
    "most_common_shapes = most_common_shapes.merge(data.routes, how = 'left', on = 'route_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f7cfd2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\.conda\\envs\\rtd_data_env\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:127: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    }
   ],
   "source": [
    "# make shapely points\n",
    "# https://www.geeksforgeeks.org/apply-function-to-every-row-in-a-pandas-dataframe/\n",
    "data.shapes['pt'] = data.shapes.apply(lambda row: shapely.geometry.Point((float(row['shape_pt_lon']), float(row['shape_pt_lat']))), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f77b9d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shapes['shape_pt_sequence'] = pd.to_numeric(data.shapes['shape_pt_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9571f5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\.conda\\envs\\rtd_data_env\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:127: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    }
   ],
   "source": [
    "# construct sorted list of shapely points\n",
    "# custom aggregation function: https://stackoverflow.com/a/10964938\n",
    "\n",
    "def make_linestring_of_points(sub_df):\n",
    "    sorted_df = sub_df.sort_values(by = 'shape_pt_sequence')\n",
    "    return shapely.geometry.LineString(list(sorted_df['pt']))\n",
    "\n",
    "constructed_shapes = data.shapes.groupby('shape_id').apply(make_linestring_of_points).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3672e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in the other route attributes\n",
    "final = most_common_shapes.merge(constructed_shapes, how = 'left', on = 'shape_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cdce59ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a \"geometry\" column for geopandas\n",
    "final['geometry'] = final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2cd8fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the geopandas geodataframe\n",
    "final_gdf = geopandas.GeoDataFrame(data = final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0ba0db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the column that's a list of shapely points\n",
    "final_gdf = final_gdf.drop(0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "80a09727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gis.stackexchange.com/questions/11910/meaning-of-simplifys-tolerance-parameter\n",
    "final_gdf['geometry'] = final_gdf['geometry'].simplify(.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8fbd55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file as geojson (this saves locally)\n",
    "with open('route_shapes_simplified_linestring.geojson', 'w') as f:\n",
    "    f.write(final_gdf.loc[(final_gdf['route_type'] == '3')].to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e4fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('rtd_data_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a451d7a41f216d3b225fc4be1924d6ac6b639fabac24dabdfa0cec3d0a5c1d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
