{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ff509f7",
   "metadata": {},
   "source": [
    "# Notebook with GTFS methods\n",
    "\n",
    "Goals: \n",
    "\n",
    "* Make a way to calculate the scheduled number of current active trips given a date, time, and route. \n",
    "    - Take datetime and find what services are active on that date \n",
    "    - Find what trips run on those services + route \n",
    "    - Find which of those trips are \"in progress\" per stop_times\n",
    "* ~Output most common shape by route~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ffac7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "\n",
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import requests\n",
    "import pendulum\n",
    "from io import BytesIO\n",
    "import shapely\n",
    "import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a22d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if \"private\", will assume you have write permissions and allow you to write; else will not attempt to write files\n",
    "BUCKET_TYPE = \"private\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b41f5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local \n",
    "# CTA_GTFS = zipfile.ZipFile('cta_gtfs_20220509.zip')\n",
    "# s3\n",
    "# follow https://pythonguides.com/download-zip-file-from-url-using-python/\n",
    "# CTA_GTFS = zipfile.ZipFile(BytesIO(requests.get('https://chn-ghost-buses-public.s3.us-east-2.amazonaws.com/cta_static_gtfs/cta_gtfs_20220509.zip').content))\n",
    "# cta website\n",
    "\n",
    "# VERSION_ID = '20220718'\n",
    "\n",
    "RTD_GTFS = zipfile.ZipFile('../../utils/utils/gtfs/google_transit_20231504.zip') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60357a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTFSFeed:\n",
    "   \"\"\" Static GTFS management \"\"\"\n",
    "   def __init__(self, gtfs_zipfile):\n",
    "        self.gtfs_zipfile = gtfs_zipfile\n",
    "        self.feed_start = None\n",
    "        self.feed_end = None\n",
    "        try: \n",
    "            with self.gtfs_zipfile.open('stops.txt') as file:\n",
    "                    self.stops = pd.read_csv(file, dtype = 'object')\n",
    "                    print(\"stops.txt loaded\")\n",
    "            with self.gtfs_zipfile.open('stop_times.txt') as file:\n",
    "                    self.stop_times = pd.read_csv(file, dtype = 'object')\n",
    "                    print(\"stop_times.txt loaded\")\n",
    "            with self.gtfs_zipfile.open('routes.txt') as file:\n",
    "                    self.routes = pd.read_csv(file, dtype = 'object')\n",
    "                    print(\"routes.txt loaded\")\n",
    "            with self.gtfs_zipfile.open('trips.txt') as file:\n",
    "                    self.trips = pd.read_csv(file, dtype = 'object')\n",
    "                    print(\"trips.txt loaded\")\n",
    "        except KeyError as e:\n",
    "            print(\"GTFS is missing required file\")\n",
    "            print(e)\n",
    "        if 'calendar.txt' in self.gtfs_zipfile.namelist():\n",
    "                with self.gtfs_zipfile.open('calendar.txt') as file:\n",
    "                        self.calendar = pd.read_csv(file, dtype = 'object')\n",
    "                        print(\"calendar.txt loaded\")\n",
    "        else:\n",
    "            print(\"no calendar.txt found\")\n",
    "        if 'calendar_dates.txt' in self.gtfs_zipfile.namelist():\n",
    "                with self.gtfs_zipfile.open('calendar_dates.txt') as file:\n",
    "                        self.calendar_dates = pd.read_csv(file, dtype = 'object')\n",
    "                        print(\"calendar_dates.txt loaded\")\n",
    "        else:\n",
    "            print(\"no calendar_dates.txt found\")\n",
    "        if 'shapes.txt' in self.gtfs_zipfile.namelist():\n",
    "                with self.gtfs_zipfile.open('shapes.txt') as file:\n",
    "                        self.shapes = pd.read_csv(file, dtype = 'object')\n",
    "                        print(\"shapes.txt loaded\")\n",
    "        else:\n",
    "            print(\"no shapes.txt found\")\n",
    "        if 'feed_info.txt' in self.gtfs_zipfile.namelist():\n",
    "                with self.gtfs_zipfile.open('feed_info.txt') as file:\n",
    "                        self.feed_info = pd.read_csv(file, dtype = 'object')\n",
    "                        print(\"feed_info.txt loaded\")\n",
    "                self.feed_start = pd.to_datetime(self.feed_info['feed_start_date'][0])\n",
    "                self.feed_end = pd.to_datetime(self.feed_info['feed_end_date'][0])\n",
    "        else:\n",
    "            print(\"no feed_info.txt found\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a4870d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stops.txt loaded\n",
      "stop_times.txt loaded\n",
      "routes.txt loaded\n",
      "trips.txt loaded\n",
      "calendar.txt loaded\n",
      "calendar_dates.txt loaded\n",
      "shapes.txt loaded\n",
      "feed_info.txt loaded\n"
     ]
    }
   ],
   "source": [
    "data = GTFSFeed(RTD_GTFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e879fed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-08-19 00:00:00')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feed_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf546a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>monday</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>wednesday</th>\n",
       "      <th>thursday</th>\n",
       "      <th>friday</th>\n",
       "      <th>saturday</th>\n",
       "      <th>sunday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SA_merged_114569136</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SA_3340</td>\n",
       "      <td>20230403</td>\n",
       "      <td>20230501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MT_3340</td>\n",
       "      <td>20230403</td>\n",
       "      <td>20230501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WK_3340</td>\n",
       "      <td>20230403</td>\n",
       "      <td>20230501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR_merged_114569130</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MT_merged_114569127</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FR_merged_114569123</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FR_3340</td>\n",
       "      <td>20230403</td>\n",
       "      <td>20230501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WK_merged_114569132</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WK_merged_114569125</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SU_merged_114569126</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P_Fri_merged_114569135</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SU_3340</td>\n",
       "      <td>20230403</td>\n",
       "      <td>20230501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P_Fri_merged_114569128</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DPSWK_merged_114569124</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DPSWK_merged_114569131</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SA_merged_114569129</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MT_merged_114569134</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                service_id start_date  end_date monday tuesday wednesday  \\\n",
       "0      SA_merged_114569136   20230528  20230819      0       0         0   \n",
       "1                  SA_3340   20230403  20230501      0       0         0   \n",
       "2                  MT_3340   20230403  20230501      1       1         1   \n",
       "3                  WK_3340   20230403  20230501      1       1         1   \n",
       "4      FR_merged_114569130   20230528  20230819      0       0         0   \n",
       "5      MT_merged_114569127   20230108  20230527      1       1         1   \n",
       "6      FR_merged_114569123   20230108  20230527      0       0         0   \n",
       "7                  FR_3340   20230403  20230501      0       0         0   \n",
       "8      WK_merged_114569132   20230528  20230819      1       1         1   \n",
       "9      WK_merged_114569125   20230108  20230527      1       1         1   \n",
       "10     SU_merged_114569126   20230108  20230527      0       0         0   \n",
       "11  P_Fri_merged_114569135   20230528  20230819      0       0         0   \n",
       "12                 SU_3340   20230403  20230501      0       0         0   \n",
       "13  P_Fri_merged_114569128   20230108  20230527      0       0         0   \n",
       "14  DPSWK_merged_114569124   20230108  20230527      1       1         1   \n",
       "15  DPSWK_merged_114569131   20230528  20230819      1       1         1   \n",
       "16     SA_merged_114569129   20230108  20230527      0       0         0   \n",
       "17     SU_merged_114569133   20230528  20230819      0       0         0   \n",
       "18     MT_merged_114569134   20230528  20230819      1       1         1   \n",
       "\n",
       "   thursday friday saturday sunday  \n",
       "0         0      0        1      0  \n",
       "1         0      0        1      0  \n",
       "2         1      0        0      0  \n",
       "3         1      1        0      0  \n",
       "4         0      1        0      0  \n",
       "5         1      0        0      0  \n",
       "6         0      1        0      0  \n",
       "7         0      1        0      0  \n",
       "8         1      1        0      0  \n",
       "9         1      1        0      0  \n",
       "10        0      0        0      1  \n",
       "11        0      1        0      0  \n",
       "12        0      0        0      1  \n",
       "13        0      1        0      0  \n",
       "14        1      1        0      0  \n",
       "15        1      1        0      0  \n",
       "16        0      0        1      0  \n",
       "17        0      0        0      1  \n",
       "18        1      0        0      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Convert calen\n",
    "data.calendar\n",
    "# data.calendar_dates\n",
    "# data.trips\n",
    "# data.stop_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "740f84c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hour(s):\n",
    "    parts = s.split(':')\n",
    "    assert len(parts)==3\n",
    "    hour = int(parts[0])\n",
    "    if hour >= 24:\n",
    "        hour -= 24\n",
    "    return hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22148f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>monday</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>wednesday</th>\n",
       "      <th>thursday</th>\n",
       "      <th>friday</th>\n",
       "      <th>saturday</th>\n",
       "      <th>sunday</th>\n",
       "      <th>start_date_dt</th>\n",
       "      <th>end_date_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SA_merged_114569136</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-28 00:00:00-06:00</td>\n",
       "      <td>2023-08-19 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SA_3340</td>\n",
       "      <td>20230403</td>\n",
       "      <td>20230501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-03 00:00:00-06:00</td>\n",
       "      <td>2023-05-01 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MT_3340</td>\n",
       "      <td>20230403</td>\n",
       "      <td>20230501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-03 00:00:00-06:00</td>\n",
       "      <td>2023-05-01 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WK_3340</td>\n",
       "      <td>20230403</td>\n",
       "      <td>20230501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-03 00:00:00-06:00</td>\n",
       "      <td>2023-05-01 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR_merged_114569130</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-28 00:00:00-06:00</td>\n",
       "      <td>2023-08-19 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MT_merged_114569127</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-08 00:00:00-07:00</td>\n",
       "      <td>2023-05-27 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FR_merged_114569123</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-08 00:00:00-07:00</td>\n",
       "      <td>2023-05-27 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FR_3340</td>\n",
       "      <td>20230403</td>\n",
       "      <td>20230501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-03 00:00:00-06:00</td>\n",
       "      <td>2023-05-01 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WK_merged_114569132</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-28 00:00:00-06:00</td>\n",
       "      <td>2023-08-19 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WK_merged_114569125</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-08 00:00:00-07:00</td>\n",
       "      <td>2023-05-27 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SU_merged_114569126</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-08 00:00:00-07:00</td>\n",
       "      <td>2023-05-27 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P_Fri_merged_114569135</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-28 00:00:00-06:00</td>\n",
       "      <td>2023-08-19 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SU_3340</td>\n",
       "      <td>20230403</td>\n",
       "      <td>20230501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-03 00:00:00-06:00</td>\n",
       "      <td>2023-05-01 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P_Fri_merged_114569128</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-08 00:00:00-07:00</td>\n",
       "      <td>2023-05-27 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DPSWK_merged_114569124</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-08 00:00:00-07:00</td>\n",
       "      <td>2023-05-27 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DPSWK_merged_114569131</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-28 00:00:00-06:00</td>\n",
       "      <td>2023-08-19 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SA_merged_114569129</td>\n",
       "      <td>20230108</td>\n",
       "      <td>20230527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-08 00:00:00-07:00</td>\n",
       "      <td>2023-05-27 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-28 00:00:00-06:00</td>\n",
       "      <td>2023-08-19 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MT_merged_114569134</td>\n",
       "      <td>20230528</td>\n",
       "      <td>20230819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-28 00:00:00-06:00</td>\n",
       "      <td>2023-08-19 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                service_id start_date  end_date monday tuesday wednesday  \\\n",
       "0      SA_merged_114569136   20230528  20230819      0       0         0   \n",
       "1                  SA_3340   20230403  20230501      0       0         0   \n",
       "2                  MT_3340   20230403  20230501      1       1         1   \n",
       "3                  WK_3340   20230403  20230501      1       1         1   \n",
       "4      FR_merged_114569130   20230528  20230819      0       0         0   \n",
       "5      MT_merged_114569127   20230108  20230527      1       1         1   \n",
       "6      FR_merged_114569123   20230108  20230527      0       0         0   \n",
       "7                  FR_3340   20230403  20230501      0       0         0   \n",
       "8      WK_merged_114569132   20230528  20230819      1       1         1   \n",
       "9      WK_merged_114569125   20230108  20230527      1       1         1   \n",
       "10     SU_merged_114569126   20230108  20230527      0       0         0   \n",
       "11  P_Fri_merged_114569135   20230528  20230819      0       0         0   \n",
       "12                 SU_3340   20230403  20230501      0       0         0   \n",
       "13  P_Fri_merged_114569128   20230108  20230527      0       0         0   \n",
       "14  DPSWK_merged_114569124   20230108  20230527      1       1         1   \n",
       "15  DPSWK_merged_114569131   20230528  20230819      1       1         1   \n",
       "16     SA_merged_114569129   20230108  20230527      0       0         0   \n",
       "17     SU_merged_114569133   20230528  20230819      0       0         0   \n",
       "18     MT_merged_114569134   20230528  20230819      1       1         1   \n",
       "\n",
       "   thursday friday saturday sunday             start_date_dt  \\\n",
       "0         0      0        1      0 2023-05-28 00:00:00-06:00   \n",
       "1         0      0        1      0 2023-04-03 00:00:00-06:00   \n",
       "2         1      0        0      0 2023-04-03 00:00:00-06:00   \n",
       "3         1      1        0      0 2023-04-03 00:00:00-06:00   \n",
       "4         0      1        0      0 2023-05-28 00:00:00-06:00   \n",
       "5         1      0        0      0 2023-01-08 00:00:00-07:00   \n",
       "6         0      1        0      0 2023-01-08 00:00:00-07:00   \n",
       "7         0      1        0      0 2023-04-03 00:00:00-06:00   \n",
       "8         1      1        0      0 2023-05-28 00:00:00-06:00   \n",
       "9         1      1        0      0 2023-01-08 00:00:00-07:00   \n",
       "10        0      0        0      1 2023-01-08 00:00:00-07:00   \n",
       "11        0      1        0      0 2023-05-28 00:00:00-06:00   \n",
       "12        0      0        0      1 2023-04-03 00:00:00-06:00   \n",
       "13        0      1        0      0 2023-01-08 00:00:00-07:00   \n",
       "14        1      1        0      0 2023-01-08 00:00:00-07:00   \n",
       "15        1      1        0      0 2023-05-28 00:00:00-06:00   \n",
       "16        0      0        1      0 2023-01-08 00:00:00-07:00   \n",
       "17        0      0        0      1 2023-05-28 00:00:00-06:00   \n",
       "18        1      0        0      0 2023-05-28 00:00:00-06:00   \n",
       "\n",
       "                 end_date_dt  \n",
       "0  2023-08-19 00:00:00-06:00  \n",
       "1  2023-05-01 00:00:00-06:00  \n",
       "2  2023-05-01 00:00:00-06:00  \n",
       "3  2023-05-01 00:00:00-06:00  \n",
       "4  2023-08-19 00:00:00-06:00  \n",
       "5  2023-05-27 00:00:00-06:00  \n",
       "6  2023-05-27 00:00:00-06:00  \n",
       "7  2023-05-01 00:00:00-06:00  \n",
       "8  2023-08-19 00:00:00-06:00  \n",
       "9  2023-05-27 00:00:00-06:00  \n",
       "10 2023-05-27 00:00:00-06:00  \n",
       "11 2023-08-19 00:00:00-06:00  \n",
       "12 2023-05-01 00:00:00-06:00  \n",
       "13 2023-05-27 00:00:00-06:00  \n",
       "14 2023-05-27 00:00:00-06:00  \n",
       "15 2023-08-19 00:00:00-06:00  \n",
       "16 2023-05-27 00:00:00-06:00  \n",
       "17 2023-08-19 00:00:00-06:00  \n",
       "18 2023-08-19 00:00:00-06:00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.calendar['start_date_dt'] = pd.to_datetime(data.calendar['start_date'], format='%Y%m%d' ).dt.tz_localize('America/Denver')\n",
    "data.calendar['end_date_dt'] = pd.to_datetime(data.calendar['end_date'], format='%Y%m%d' ).dt.tz_localize('America/Denver')\n",
    "data.calendar_dates['date_dt'] = pd.to_datetime(data.calendar_dates['date'], format='%Y%m%d' ).dt.tz_localize('America/Denver')\n",
    "\n",
    "# extract hour from stop_times timestamps \n",
    "data.stop_times['arrival_hour'] = data.stop_times.arrival_time.apply(lambda x: get_hour(x))\n",
    "data.stop_times['departure_hour'] = data.stop_times.departure_time.apply(lambda x: get_hour(x))\n",
    "data.calendar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b9217f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def format_dates_hours(data):\n",
    "#     # convert string dates to actual datetimes in calendar.txt and calendar_dates.txt\n",
    "#     data.calendar['start_date_dt'] = data.calendar['start_date'].apply(lambda x: pendulum.from_format(x, 'YYYYMMDD', tz='America/Denver'))\n",
    "#     data.calendar['end_date_dt'] = data.calendar['end_date'].apply(lambda x: pendulum.from_format(x, 'YYYYMMDD', tz='America/Denver'))\n",
    "#     data.calendar_dates['date_dt'] = data.calendar_dates['date'].apply(lambda x: pendulum.from_format(x, 'YYYYMMDD', tz='America/Denver'))\n",
    "    \n",
    "#     # extract hour from stop_times timestamps \n",
    "#     data.stop_times['arrival_hour'] = data.stop_times.arrival_time.apply(lambda x: get_hour(x))\n",
    "#     data.stop_times['departure_hour'] = data.stop_times.departure_time.apply(lambda x: get_hour(x))\n",
    "    \n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a43200f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = format_dates_hours(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fc1da23",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_date_range = pd.DataFrame(pd.date_range(data.feed_start, data.feed_end, tz = 'America/Denver'), columns = ['raw_date'])\n",
    "    \n",
    "#     # cross join calendar index with actual calendar to get all combos of possible dates & services \n",
    "calendar_cross = calendar_date_range.merge(data.calendar, how = \"cross\")\n",
    "\n",
    "#     # extract day of week from date index date\n",
    "calendar_cross['dayofweek'] = calendar_cross['raw_date'].dt.dayofweek\n",
    "calendar_cross\n",
    "\n",
    "    # take wide calendar data (one col per day of week) and make it long (one row per day of week)\n",
    "scheduled_service = calendar_cross.melt(id_vars = ['raw_date', 'start_date', 'end_date', 'service_id', 'dayofweek'], var_name = 'cal_dayofweek', value_name = 'cal_val')\n",
    "\n",
    "# #     # map the calendar input strings to day of week integers to align w pandas dayofweek output\n",
    "scheduled_service['cal_daynum'] = scheduled_service['cal_dayofweek'].map({\n",
    "    'monday': 0,\n",
    "    'tuesday': 1,\n",
    "    'wednesday': 2,\n",
    "    'thursday': 3,\n",
    "    'friday': 4,\n",
    "    'saturday': 5,\n",
    "    'sunday': 6\n",
    "})\n",
    "scheduled_service = scheduled_service[(scheduled_service.dayofweek == scheduled_service.cal_daynum) & \n",
    "                                   (scheduled_service.start_date <= scheduled_service.raw_date) &\n",
    "                                   (scheduled_service.end_date >= scheduled_service.raw_date)]\n",
    "    \n",
    "# now merge in calendar dates to the datetime index to get overrides\n",
    "scheduled_service = scheduled_service.merge(data.calendar_dates, how = 'outer', left_on = ['raw_date', 'service_id'], right_on = ['date_dt', 'service_id'])\n",
    "\n",
    "# # now add a service happened flag for dates where the schedule indicates that this service occurred\n",
    "# # i.e.: calendar has a service indicator of 1 and there's no exception type from calendar_dates\n",
    "# # OR calendar_dates has exception type of 1\n",
    "# # otherwise no service \n",
    "# # https://stackoverflow.com/questions/21415661/logical-operators-for-boolean-indexing-in-pandas\n",
    "scheduled_service['scheduled_service_flag'] = ((scheduled_service['cal_val'] == '1') & \n",
    "                                        scheduled_service['exception_type'].isnull()) | (scheduled_service['exception_type'] == '1')\n",
    "# Note: Really a \"service_scheduled\", not \"service_happened\"\n",
    "\n",
    "\n",
    "\n",
    "# # now fill in rows where calendar_dates had a date outside the bounds of the datetime index, so raw_date is always populated\n",
    "scheduled_service['raw_date'] = scheduled_service['raw_date'].fillna(scheduled_service['date_dt'])\n",
    "\n",
    "# # filter to only rows where service occurred\n",
    "scheduled_service = scheduled_service[scheduled_service.scheduled_service_flag]\n",
    "\n",
    "# # join trips to only service that occurred\n",
    "trips_scheduled = data.trips.merge(scheduled_service, how = 'left', on = 'service_id')\n",
    "\n",
    "\n",
    "# \n",
    "# # get only the trip / hour combos that actually occurred\n",
    "# Drop this, since it's assuming one-stop-per-trip\n",
    "# trip_stop_hours = data.stop_times[['trip_id', 'arrival_hour']].drop_duplicates()\n",
    "\n",
    "# # now join\n",
    "# # result has one row per date + row from trips.txt (incl. route) + hour\n",
    "# trip_summary = trips_happened.merge(trip_stop_hours, how = \"left\", on = \"trip_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7d967da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stops - reduce fields to not-derivable \n",
    "# stops_scheduled = \n",
    "trips_scheduled.head()\n",
    "trips_scheduled_keep_cols = ['block_id',\t'route_id',\t'direction_id',\t'trip_headsign',\t'shape_id',\t'service_id',\t'trip_id',\t'raw_date']\n",
    "stop_time_keep_cols = ['trip_id',\t'arrival_time',\t'departure_time',\t'stop_id',\t'stop_sequence',\t'stop_headsign',\t'pickup_type',\t'drop_off_type',\t'shape_dist_traveled',\t'timepoint'] \n",
    "# Note that 'shape_dist_traveled',\t'timepoint' are not used for RTD, but could be useful elsewhere\n",
    "data.stop_times\n",
    "stops_scheduled = trips_scheduled[trips_scheduled_keep_cols].merge(data.stop_times[stop_time_keep_cols], on = 'trip_id' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b889d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8db4413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.stop_times.astype({'stop_sequence': 'int32'}).groupby('trip_id')['stop_sequence'].agg('max').median() #.plot(kind='hist') # value_counts() #plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7d5c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "983ca911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a529d929ec4002be2dba36775a9276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/59346093 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389a212361784902bb883ec529bdd1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/59346093 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transform trips + stops into easily-worked-with final datasets\n",
    "\n",
    "\n",
    "# Stops:\n",
    "# * Convert arrival_time and departure_time into proper datetimes. Note: Slow!\n",
    "# Is there a quicker way to run this? String processing only, then to_datetime?? ~3 hours per column right now.\n",
    "def combine_day_stop(raw_dt, stop_time):\n",
    "    \"\"\" Only treat as string unless not possible elsewhere - to_datetime is incredibly slow in apply \"\"\"\n",
    "    try:\n",
    "        if int(stop_time[0:2]) > 23:\n",
    "            # Replace hour with (hour-24). Add one day to raw_dt.\n",
    "            hour_replace = str(int(stop_time[0:2]) - 24).zfill(2)\n",
    "            stop_time = hour_replace + stop_time[2:]\n",
    "            arrival_time = pd.to_datetime(f\"{raw_dt.date() + pd.Timedelta('1d')}T{stop_time}\").tz_localize(raw_dt.tz)\n",
    "        else:\n",
    "            arrival_time = pd.to_datetime(f\"{raw_dt.date()}T{stop_time}\").tz_localize(raw_dt.tz) # f\"{raw_dt.date()} {stop_time}\" \n",
    "        return arrival_time\n",
    "    except:\n",
    "        return None\n",
    "# Parallel-process \"apply\". Can't easily be vectorized.\n",
    "stops_scheduled['arrival_datetime'] = stops_scheduled.swifter.apply(lambda x: combine_day_stop(x.raw_date, x.arrival_time), axis = 1)\n",
    "stops_scheduled['departure_datetime'] = stops_scheduled.swifter.apply(lambda x: combine_day_stop(x.raw_date, x.departure_time), axis = 1)\n",
    "\n",
    "# # stops_scheduled['arrival_datetime'] = stops_scheduled.apply(lambda x: combine_day_stop(x.raw_date, x.arrival_time), axis = 1)\n",
    "# # stops_scheduled['departure_datetime'] = stops_scheduled.apply(lambda x: combine_day_stop(x.raw_date, x.departure_time), axis = 1)\n",
    "# stops_scheduled['arrival_datetime'] = pd.to_datetime(stops_scheduled['arrival_datetime']).tz_localize('America/Denver')\n",
    "# stops_scheduled['departure_datetime'] = pd.to_datetime(stops_scheduled['departure_datetime']).tz_localize('America/Denver')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca31230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trips:\n",
    "# * rename raw_date to scheduled_service_date\n",
    "trips_scheduled = trips_scheduled[trips_scheduled_keep_cols]\n",
    "trips_scheduled_rename_dict = {'raw_date':'scheduled_service_date'}\n",
    "trips_scheduled = trips_scheduled.rename(trips_scheduled_rename_dict, axis = 1)\n",
    "\n",
    "# Stops ctd\n",
    "# * Rename \"raw_date\" to \"service_date\"\n",
    "stops_scheduled_rename_dict = {'raw_date':'service_date'}\n",
    "stops_scheduled = stops_scheduled.rename(stops_scheduled_rename_dict, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9750c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "trips_scheduled.to_parquet('trips_scheduled.parquet')\n",
    "stops_scheduled.to_parquet('stops_scheduled.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ca10ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_scheduled.to_parquet(f's3://rtd-ghost-buses-{BUCKET_TYPE}/schedules/trips_scheduled.parquet', index = False)\n",
    "stops_scheduled.to_parquet(f's3://rtd-ghost-buses-{BUCKET_TYPE}/schedules/stops_scheduled.parquet', index = False)\n",
    "# Output\n",
    "# stops_scheduled - dataframe with all possible scheduled stops - ['trip_id',\t'arrival_time',\t'departure_time',\t'stop_id',\t'stop_sequence',\t'stop_headsign',\t'pickup_type',\t'drop_off_type',\t'shape_dist_traveled',\t'timepoint'] \n",
    "# trips_scheduled - dataframe with all possible scheduled trips - ['block_id',\t'route_id',\t'direction_id',\t'trip_headsign',\t'shape_id',\t'service_id',\t'trip_id',\t'raw_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccef4637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>direction_id</th>\n",
       "      <th>trip_headsign</th>\n",
       "      <th>shape_id</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>scheduled_service_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b_76  4</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>US36 &amp; Bfld</td>\n",
       "      <td>1241914</td>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>114458891</td>\n",
       "      <td>2023-05-29 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b_76  4</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>US36 &amp; Bfld</td>\n",
       "      <td>1241914</td>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>114458891</td>\n",
       "      <td>2023-07-04 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b_76  4</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>US36 &amp; Bfld</td>\n",
       "      <td>1241914</td>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>114458891</td>\n",
       "      <td>2023-05-28 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b_76  4</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>US36 &amp; Bfld</td>\n",
       "      <td>1241914</td>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>114458891</td>\n",
       "      <td>2023-06-04 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b_76  4</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>US36 &amp; Bfld</td>\n",
       "      <td>1241914</td>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>114458891</td>\n",
       "      <td>2023-06-11 00:00:00-06:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  block_id route_id direction_id trip_headsign shape_id           service_id  \\\n",
       "0  b_76  4       76            0   US36 & Bfld  1241914  SU_merged_114569133   \n",
       "1  b_76  4       76            0   US36 & Bfld  1241914  SU_merged_114569133   \n",
       "2  b_76  4       76            0   US36 & Bfld  1241914  SU_merged_114569133   \n",
       "3  b_76  4       76            0   US36 & Bfld  1241914  SU_merged_114569133   \n",
       "4  b_76  4       76            0   US36 & Bfld  1241914  SU_merged_114569133   \n",
       "\n",
       "     trip_id    scheduled_service_date  \n",
       "0  114458891 2023-05-29 00:00:00-06:00  \n",
       "1  114458891 2023-07-04 00:00:00-06:00  \n",
       "2  114458891 2023-05-28 00:00:00-06:00  \n",
       "3  114458891 2023-06-04 00:00:00-06:00  \n",
       "4  114458891 2023-06-11 00:00:00-06:00  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_scheduled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27f517a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>direction_id</th>\n",
       "      <th>trip_headsign</th>\n",
       "      <th>shape_id</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>service_date</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_headsign</th>\n",
       "      <th>pickup_type</th>\n",
       "      <th>drop_off_type</th>\n",
       "      <th>shape_dist_traveled</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>arrival_datetime</th>\n",
       "      <th>departure_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b_76  4</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>US36 &amp; Bfld</td>\n",
       "      <td>1241914</td>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>114458891</td>\n",
       "      <td>2023-05-29 00:00:00-06:00</td>\n",
       "      <td>08:22:00</td>\n",
       "      <td>08:22:00</td>\n",
       "      <td>24858</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 08:22:00-06:00</td>\n",
       "      <td>2023-05-29 08:22:00-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b_76  4</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>US36 &amp; Bfld</td>\n",
       "      <td>1241914</td>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>114458891</td>\n",
       "      <td>2023-05-29 00:00:00-06:00</td>\n",
       "      <td>08:22:45</td>\n",
       "      <td>08:22:45</td>\n",
       "      <td>25312</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 08:22:45-06:00</td>\n",
       "      <td>2023-05-29 08:22:45-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b_76  4</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>US36 &amp; Bfld</td>\n",
       "      <td>1241914</td>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>114458891</td>\n",
       "      <td>2023-05-29 00:00:00-06:00</td>\n",
       "      <td>08:23:40</td>\n",
       "      <td>08:23:40</td>\n",
       "      <td>17023</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 08:23:40-06:00</td>\n",
       "      <td>2023-05-29 08:23:40-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b_76  4</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>US36 &amp; Bfld</td>\n",
       "      <td>1241914</td>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>114458891</td>\n",
       "      <td>2023-05-29 00:00:00-06:00</td>\n",
       "      <td>08:24:24</td>\n",
       "      <td>08:24:24</td>\n",
       "      <td>17025</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 08:24:24-06:00</td>\n",
       "      <td>2023-05-29 08:24:24-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b_76  4</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>US36 &amp; Bfld</td>\n",
       "      <td>1241914</td>\n",
       "      <td>SU_merged_114569133</td>\n",
       "      <td>114458891</td>\n",
       "      <td>2023-05-29 00:00:00-06:00</td>\n",
       "      <td>08:25:08</td>\n",
       "      <td>08:25:08</td>\n",
       "      <td>16946</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 08:25:08-06:00</td>\n",
       "      <td>2023-05-29 08:25:08-06:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  block_id route_id direction_id trip_headsign shape_id           service_id  \\\n",
       "0  b_76  4       76            0   US36 & Bfld  1241914  SU_merged_114569133   \n",
       "1  b_76  4       76            0   US36 & Bfld  1241914  SU_merged_114569133   \n",
       "2  b_76  4       76            0   US36 & Bfld  1241914  SU_merged_114569133   \n",
       "3  b_76  4       76            0   US36 & Bfld  1241914  SU_merged_114569133   \n",
       "4  b_76  4       76            0   US36 & Bfld  1241914  SU_merged_114569133   \n",
       "\n",
       "     trip_id              service_date arrival_time departure_time stop_id  \\\n",
       "0  114458891 2023-05-29 00:00:00-06:00     08:22:00       08:22:00   24858   \n",
       "1  114458891 2023-05-29 00:00:00-06:00     08:22:45       08:22:45   25312   \n",
       "2  114458891 2023-05-29 00:00:00-06:00     08:23:40       08:23:40   17023   \n",
       "3  114458891 2023-05-29 00:00:00-06:00     08:24:24       08:24:24   17025   \n",
       "4  114458891 2023-05-29 00:00:00-06:00     08:25:08       08:25:08   16946   \n",
       "\n",
       "  stop_sequence stop_headsign pickup_type drop_off_type shape_dist_traveled  \\\n",
       "0             1           NaN         NaN             1                 NaN   \n",
       "1             2           NaN         NaN           NaN                 NaN   \n",
       "2             3           NaN         NaN           NaN                 NaN   \n",
       "3             4           NaN         NaN           NaN                 NaN   \n",
       "4             5           NaN         NaN           NaN                 NaN   \n",
       "\n",
       "  timepoint          arrival_datetime        departure_datetime  \n",
       "0       NaN 2023-05-29 08:22:00-06:00 2023-05-29 08:22:00-06:00  \n",
       "1       NaN 2023-05-29 08:22:45-06:00 2023-05-29 08:22:45-06:00  \n",
       "2       NaN 2023-05-29 08:23:40-06:00 2023-05-29 08:23:40-06:00  \n",
       "3       NaN 2023-05-29 08:24:24-06:00 2023-05-29 08:24:24-06:00  \n",
       "4       NaN 2023-05-29 08:25:08-06:00 2023-05-29 08:25:08-06:00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops_scheduled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2f72457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b870c6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0050b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# departure_datetime.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e563dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity-check on arrival times. How many NaT? How many overlaps elsewhere?\n",
    "# 112 NaT - can be neglected for now.\n",
    "# Often have 99 stops at the same time. All unique, often on the quarter-hour \n",
    "\n",
    "# stops_scheduled['arrival_datetime'].value_counts()\n",
    "# How many have 7:15 arrival? 99? Why?\n",
    "stops_scheduled.loc[stops_scheduled[\"arrival_datetime\"]==pd.to_datetime(\"2023-04-27 07:15:00-06:00\")].sort_values('route_id').to_csv('duplicate_check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecfec21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023-01-08 02:22:00-07:00      1\n",
       "2023-01-08 02:22:47-07:00      1\n",
       "2023-01-08 02:23:21-07:00      1\n",
       "2023-01-08 02:23:59-07:00      1\n",
       "2023-01-08 02:24:39-07:00      1\n",
       "                            ... \n",
       "2023-08-20 02:19:00-06:00      1\n",
       "2023-08-20 02:23:00-06:00      1\n",
       "2023-08-20 02:28:00-06:00      1\n",
       "2023-08-20 02:34:00-06:00      1\n",
       "NaT                          112\n",
       "Name: departure_datetime, Length: 15185296, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops_scheduled['departure_datetime'].value_counts(dropna=False).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9340c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_scheduled.shape # 59 million scheduled stops!\n",
    "# How many before Memorial Day? 37.7 million.\n",
    "len(stops_scheduled.loc[stops_scheduled['raw_date'] < pd.to_datetime('2023-05-29 00:00:00-06:00')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fdc16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity-checks:\n",
    "trips_scheduled\n",
    "# raw_date + trip_id + service_id\n",
    "trips_scheduled.sort_values(['raw_date', 'trip_id', 'service_id'])\n",
    "# 1.5 million trips scheduled between Jan - May. Sanity-check:\n",
    "trip_days = 160 # approximate\n",
    "unique_routes = len(trips_scheduled['route_id'].unique()) *2 # Double for direction\n",
    "len(trips_scheduled) / trip_days / unique_routes # ~40ish round-trips per route per day. High? Reasonable?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What other sanity-checks? Plot time series of trips / day\n",
    "trips_scheduled.sort_values(['raw_date', 'trip_id', 'service_id']).groupby('raw_date')['trip_id'].agg('count').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25d1ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique routes / day? 115ish weekday, 90ish weekend\n",
    "trips_scheduled.sort_values(['raw_date', 'route_id', 'service_id']).groupby('raw_date')['route_id'].agg('nunique').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual inspection to double-check - Look at the 0\n",
    "trips_scheduled.sort_values(['raw_date', 'route_id', 'trip_id', 'service_id']).loc[(trips_scheduled.route_id == '0') & (trips_scheduled.raw_date == '2023-01-08 00:00:00-07:00')] #.head()\n",
    "# 123 rows. Double-checked against Transit, sanity-check passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183650c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.trips.loc[data.trips.trip_id.isin(['114346478','114346479','114346480','114346481'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992c5506",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.trips.loc[data.trips.trip_id.isin(['114346478','114346479','114346480','114346481'])]\n",
    "print(data.stop_times[data.stop_times.trip_id.isin(['114346478','114346479'])][['trip_id', 'departure_time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c4e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc163c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b3bb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9913b3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1950a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2c84c30",
   "metadata": {},
   "source": [
    "## Basic data transformations\n",
    "\n",
    "Ex. creating actual timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c1328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_timestamp(s, date):\n",
    "#     parts = s.split(':')\n",
    "#     assert len(parts)==3\n",
    "#     if int(parts[0]) > 23:\n",
    "#         num_parts = [int(parts[0]) - 24, int(parts[1]), int(parts[2])]\n",
    "#     else:\n",
    "#         num_parts = [int(parts[0]), int(parts[1]), int(parts[2])]\n",
    "#     return pendulum.datetime(year = date.year, month = date.month, day = date.day, hour = num_parts[0], minute = num_parts[1], second = num_parts[2])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96410a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that there are no dwell periods that cross hour boundary\n",
    "# 476 rows - arrive at 59, leave a minute or two later. 476 instances for RTD. Why does this even matter?\n",
    "# data.stop_times[data.stop_times.arrival_hour != data.stop_times.departure_hour]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7222f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad4649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_trip_summary(data):\n",
    "#     # construct a datetime index that has every day between calendar start and end \n",
    "#     calendar_date_range = pd.DataFrame(pd.date_range(min(data.calendar.start_date_dt), max(data.calendar.end_date_dt)), columns = ['raw_date'])\n",
    "    \n",
    "#     # cross join calendar index with actual calendar to get all combos of possible dates & services \n",
    "#     calendar_cross = calendar_date_range.merge(data.calendar, how = \"cross\")\n",
    "    \n",
    "#     # extract day of week from date index date\n",
    "#     calendar_cross['dayofweek'] = calendar_cross['raw_date'].dt.dayofweek\n",
    "    \n",
    "#     # take wide calendar data (one col per day of week) and make it long (one row per day of week)\n",
    "#     actual_service = calendar_cross.melt(id_vars = ['raw_date', 'start_date_dt', 'end_date_dt', 'start_date', 'end_date', 'service_id', 'dayofweek'], var_name = 'cal_dayofweek', value_name = 'cal_val')\n",
    "    \n",
    "#     # map the calendar input strings to day of week integers to align w pandas dayofweek output\n",
    "#     actual_service['cal_daynum'] = actual_service['cal_dayofweek'].map({\n",
    "#         'monday': 0,\n",
    "#         'tuesday': 1,\n",
    "#         'wednesday': 2,\n",
    "#         'thursday': 3,\n",
    "#         'friday': 4,\n",
    "#         'saturday': 5,\n",
    "#         'sunday': 6\n",
    "#     })\n",
    "    \n",
    "#     # now check for rows that \"work\"\n",
    "#     # i.e., the day of week matches between datetime index & calendar input\n",
    "#     # and the datetime index is between the calendar row's start and end dates\n",
    "#     actual_service = actual_service[(actual_service.dayofweek == actual_service.cal_daynum) & \n",
    "#                                    (actual_service.start_date_dt <= actual_service.raw_date) &\n",
    "#                                    (actual_service.end_date_dt >= actual_service.raw_date)]\n",
    "    \n",
    "#     # now merge in calendar dates to the datetime index to get overrides\n",
    "#     # TODO - localize to Mountain time\n",
    "#     actual_service = actual_service.merge(data.calendar_dates, how = 'outer', left_on = ['raw_date', 'service_id'], right_on = ['date_dt', 'service_id'])\n",
    "    \n",
    "#     # now add a service happened flag for dates where the schedule indicates that this service occurred\n",
    "#     # i.e.: calendar has a service indicator of 1 and there's no exception type from calendar_dates\n",
    "#     # OR calendar_dates has exception type of 1\n",
    "#     # otherwise no service \n",
    "#     # https://stackoverflow.com/questions/21415661/logical-operators-for-boolean-indexing-in-pandas\n",
    "#     actual_service['service_happened'] = ((actual_service['cal_val'] == '1') & \n",
    "#                                           actual_service['exception_type'].isnull()) | (actual_service['exception_type'] == '1')\n",
    "\n",
    "    \n",
    "#     # now fill in rows where calendar_dates had a date outside the bounds of the datetime index, so raw_date is always populated\n",
    "#     actual_service['raw_date'] = actual_service['raw_date'].fillna(actual_service['date_dt'])\n",
    "    \n",
    "#     # filter to only rows where service occurred\n",
    "#     service_happened = actual_service[actual_service.service_happened]\n",
    "    \n",
    "#     # join trips to only service that occurred\n",
    "#     trips_happened = data.trips.merge(service_happened, how = 'left', on = 'service_id')\n",
    "    \n",
    "#     # get only the trip / hour combos that actually occurred\n",
    "#     trip_stop_hours = data.stop_times[['trip_id', 'arrival_hour']].drop_duplicates()\n",
    "    \n",
    "#     # now join\n",
    "#     # result has one row per date + row from trips.txt (incl. route) + hour\n",
    "#     trip_summary = trips_happened.merge(trip_stop_hours, how = \"left\", on = \"trip_id\")\n",
    "    \n",
    "#     return trip_summary\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fce10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip_summary = make_trip_summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb947dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(trip_summary.dtypes)\n",
    "# print(trip_summary.shape)\n",
    "# trip_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ddd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.feed_info.feed_version[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d812de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION_ID = data.feed_info.feed_version[0]\n",
    "# def summarize_and_save(trip_summary): \n",
    "#     # now group to get trips by hour by date by route\n",
    "#     route_daily_hourly_summary = trip_summary.groupby(by = ['raw_date', 'route_id', 'arrival_hour'])['trip_id'].count().reset_index()\n",
    "\n",
    "#     route_daily_hourly_summary.rename(columns = {'arrival_hour': 'hour', 'trip_id': 'trip_count', 'raw_date': 'date'}, inplace = True)\n",
    "#     route_daily_hourly_summary.date = route_daily_hourly_summary.date.dt.date\n",
    "#     if BUCKET_TYPE == \"private\":\n",
    "#         route_daily_hourly_summary.to_csv(f's3://rtd-ghost-buses-{BUCKET_TYPE}/schedule_summaries/route_level/schedule_route_daily_hourly_summary_{VERSION_ID}.csv', index = False)\n",
    "    \n",
    "#     # now group to get trips by hour by date by route by *direction*\n",
    "#     route_dir_daily_hourly_summary = trip_summary.groupby(by = ['raw_date', 'route_id', 'direction_id', 'arrival_hour'])['trip_id'].count().reset_index()\n",
    "\n",
    "#     route_dir_daily_hourly_summary.rename(columns = {'arrival_hour': 'hour', 'trip_id': 'trip_count', 'raw_date': 'date'}, inplace = True)\n",
    "#     route_dir_daily_hourly_summary.date = route_dir_daily_hourly_summary.date.dt.date\n",
    "#     if BUCKET_TYPE == \"private\":\n",
    "#         route_dir_daily_hourly_summary.to_csv(f's3://rtd-ghost-buses-{BUCKET_TYPE}/schedule_summaries/route_dir_level/schedule_route_dir_daily_hourly_summary_{VERSION_ID}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae71821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize_and_save(trip_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dfd3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "221fd612",
   "metadata": {},
   "source": [
    "## Most common shape by route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba63340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get trip count by route, direction, shape id\n",
    "trips_by_rte_direction = data.trips.groupby(['route_id', 'shape_id', 'direction_id'])['trip_id'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7669b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only most common shape id by route, direction\n",
    "# follow: https://stackoverflow.com/a/54041328\n",
    "most_common_shapes = trips_by_rte_direction.sort_values('trip_id').drop_duplicates(['route_id','direction_id'],keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb40d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get additional route attributes\n",
    "most_common_shapes = most_common_shapes.merge(data.routes, how = 'left', on = 'route_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cfd2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make shapely points\n",
    "# https://www.geeksforgeeks.org/apply-function-to-every-row-in-a-pandas-dataframe/\n",
    "data.shapes['pt'] = data.shapes.apply(lambda row: shapely.geometry.Point((float(row['shape_pt_lon']), float(row['shape_pt_lat']))), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77b9d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shapes['shape_pt_sequence'] = pd.to_numeric(data.shapes['shape_pt_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9571f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct sorted list of shapely points\n",
    "# custom aggregation function: https://stackoverflow.com/a/10964938\n",
    "\n",
    "def make_linestring_of_points(sub_df):\n",
    "    sorted_df = sub_df.sort_values(by = 'shape_pt_sequence')\n",
    "    return shapely.geometry.LineString(list(sorted_df['pt']))\n",
    "\n",
    "constructed_shapes = data.shapes.groupby('shape_id').apply(make_linestring_of_points).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3672e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in the other route attributes\n",
    "final = most_common_shapes.merge(constructed_shapes, how = 'left', on = 'shape_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce59ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a \"geometry\" column for geopandas\n",
    "final['geometry'] = final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the geopandas geodataframe\n",
    "final_gdf = geopandas.GeoDataFrame(data = final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the column that's a list of shapely points\n",
    "final_gdf = final_gdf.drop(0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a09727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gis.stackexchange.com/questions/11910/meaning-of-simplifys-tolerance-parameter\n",
    "final_gdf['geometry'] = final_gdf['geometry'].simplify(.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file as geojson (this saves locally)\n",
    "with open('route_shapes_simplified_linestring.geojson', 'w') as f:\n",
    "    f.write(final_gdf.loc[(final_gdf['route_type'] == '3')].to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e4fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dae4f815",
   "metadata": {},
   "source": [
    "# Exploratory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfd385d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3ec208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900dfa27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('rtd_data_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a451d7a41f216d3b225fc4be1924d6ac6b639fabac24dabdfa0cec3d0a5c1d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
